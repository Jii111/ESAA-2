{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4주차_과제_2",
      "provenance": [],
      "authorship_tag": "ABX9TyPZx91IBnuKdufKnTdIBluP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 7장 앙상블 학습과 랜덤 포레스트"
      ],
      "metadata": {
        "id": "77iZvYFk87vY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 앙상블: 일련의 예측기(분류 또는 회귀)로부터 예측을 수집하면 가장 좋은 모델 하나보다 더 좋은 예측\n",
        "\n",
        "  (ex) 훈련 세트로부터 무작위로 각기 다른 서브셋을 만들어 일련의 결정트리 분류기를 훈련시킨후 가장 많은 선택을 받은 클래스를 예측으로 삼음\n",
        "\n",
        "  - 랜덤 포레스트: 결정 트리의 앙상블\n",
        "  - 배깅, 부스팅, 스태킹 등"
      ],
      "metadata": {
        "id": "HwOBENEjQiVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 투표 기반 분류기\n",
        "\n",
        "- 직접 투표 분류기: 다수결 투표로 정해지는 분류기\n",
        "- 분류기가 약한 학습기라도 충분히 많고 다양하다면, 앙상블은 강한 학습기가 될 수 있음\n",
        "- 큰 수의 법칙\n",
        "\n",
        "\n",
        "- 모든 분류기가 완벽하게 독립적이고 오차에 상관관계가 없어야 함\n",
        "- 같은 데이터로 훈련시키면 안됨-분류기들이 같은 종류의 오차를 만들기 쉽기 때문에 잘못된 클래스가 다수인 경우가 많고, 앙상블의 정확도가 낮아짐\n",
        "- 다양한 분류기를 얻는다=각기 다른 알고리즘으로 학습\n",
        "\n",
        "\n",
        "- 간접투표: 모든 분류기가 클래스의 확률을 예측할 수 있으면(predict_probs()가 있으면), 개별 분류기의 예측을 평균내어 확률이 가장 높은 클래스를 예측할 수 있음\n",
        "    - voting=\"soft\"\n",
        "    - SVC는 기본값에서는 클래스 확률을 제공하지 않으므로, probability 매개변수를 True로 지정해야 함"
      ],
      "metadata": {
        "id": "RjEHOrpJVfHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "log_clf=LogisticRegression()\n",
        "rnd_clf=RandomForestClassifier()\n",
        "svm_clf=SVC()\n",
        "\n",
        "voting_clf=VotingClassifier(\n",
        "    estimators=[('lr',log_clf),('rf',rnd_clf),('svc',svm_clf)],\n",
        "    voting='hard')"
      ],
      "metadata": {
        "id": "QTXTxhEfVd1D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples=500, noise=0.3, random_state=45)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=45)\n",
        "\n",
        "voting_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3n_WwOPZ00J",
        "outputId": "fbaf6b65-4a8b-486a-a6b0-0bcb0ae1ee06"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
              "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voting_clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKt-ja069GUK",
        "outputId": "3915e15c-eee0-43ed-bc4b-76c247896d08"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
              "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "for clf in (log_clf,rnd_clf,svm_clf,voting_clf):\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_pred=clf.predict(X_test)\n",
        "  print(clf.__class__.__name__,accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnX8_5s89GR3",
        "outputId": "638882d9-e9e8-4e05-affa-08328ed38871"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.856\n",
            "RandomForestClassifier 0.904\n",
            "SVC 0.928\n",
            "VotingClassifier 0.928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 배깅과 페이스팅\n",
        "\n",
        "- 다양한 분류기 만들기\n",
        "  - 각기 다른 훈련 알고리즘 사용\n",
        "  - 같은 알고리즘 사용, 훈련 세트의 서브셋을 무작위 구성하여 분류기 각기 다르게 학습\n",
        "- 배깅: 훈련 세트에서 중복을 허용하여 샘플링하는 방식\n",
        "- 페이스팅: 중복을 허용하지 않고 샘플링하는 방식\n",
        "\n",
        "\n",
        "- 배깅과 페이스팅에서느 같은 훈련 샘플을 여러 개의 예측기에 걸쳐 사용할 수 있음\n",
        "- 배깅만이 한 예측기를 위해 같은 훈련 샘플을 여러 번 샘플링\n",
        "\n",
        "\n",
        "- 수집함수는 분류일 때는 통계적 최빈값, 회귀일 때는 평균 계산\n",
        "- 수집함수를 통과하면 편향과 분산이 모두 감소\n",
        "- 일반적으로 앙싱블의 결과는 원본 데이터셋으로 하나의 예측기를 훈련시킬 때와 비교해 편향은 비슷하지만 분산은 줄어듦\n",
        "\n",
        "\n",
        "\n",
        "- 예측기는 병렬로 학습시킬 수 있기 때문에,배깅과 페이스팅의 인기 높"
      ],
      "metadata": {
        "id": "Y32c0B43cB7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.1 사이킷런의 배깅과 페이스팅\n",
        "- 부트 스트래핑은 각 예측기가 학습하는 서브셋에 다양성을 증가시키므로 배깅이 페이스팅보다 편향이 조금 더 높음\n",
        "- 다양성을 추가한다는 것은 예측기들의 상관관계를 줄이므로 앙상블의 분산을 감소시킴\n",
        "- 배깅이 더 나은 모델을 만들기 때문에 일반적으로 더 선호\n",
        "- 시간과 CPU 파워에 여유가 있다면 교차 검증으로 배깅과 페이스팅을 모두 평가해서 더 나은 쪽을 선택하는 것이 좋음"
      ],
      "metadata": {
        "id": "ZbLY7cv6dr4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf=BaggingClassifier(\n",
        "    DecisionTreeClassifier(),n_estimators=500,\n",
        "    max_samples=100,bootstrap=True,n_jobs=-1)\n",
        "#n_jobs=-1: 가용한 모든 코어 사용\n",
        "bag_clf.fit(X_train,y_train)\n",
        "y_pred=bag_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "8Xt3XyV29GO9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.2 oob 평가\n",
        "- BaggingClassifier는 기본값으로 중복을 허용하여(bootstrap=True) 훈련 세트의 크기만큼인 m개 샘플 선택\n",
        "- oob 샘플: 선택되지 않은 훈련 샘플의 나머지\n",
        "- oob_score=True: 훈련이 끝난 후 자동으로 oob 평가 수행\n",
        "- 결정 함수: 각 훈련 샘플의 클래스 확률"
      ],
      "metadata": {
        "id": "FWpkeq6gH2cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf=BaggingClassifier(\n",
        "    DecisionTreeClassifier(),n_estimators=500,\n",
        "    bootstrap=True,n_jobs=-1,oob_score=True)"
      ],
      "metadata": {
        "id": "fnrQAa-9H12j"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf.fit(X_train,y_train)\n",
        "bag_clf.oob_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKOi7E5t9GMQ",
        "outputId": "cd570004-9464-4a66-808c-11b081d42ec5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.888"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred=bag_clf.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzJrqpHi9GJF",
        "outputId": "7a228bc8-62d7-45e0-f36c-e71c661dd41a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.904"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf.oob_decision_function_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNHwNIpz9GGZ",
        "outputId": "ad033e1c-b64c-43fc-b303-38716a066d35"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01704545, 0.98295455],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.95939086, 0.04060914],\n",
              "       [1.        , 0.        ],\n",
              "       [0.19883041, 0.80116959],\n",
              "       [0.        , 1.        ],\n",
              "       [0.28915663, 0.71084337],\n",
              "       [0.63934426, 0.36065574],\n",
              "       [0.44059406, 0.55940594],\n",
              "       [0.77419355, 0.22580645],\n",
              "       [0.01162791, 0.98837209],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.80978261, 0.19021739],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00540541, 0.99459459],\n",
              "       [0.00537634, 0.99462366],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99408284, 0.00591716],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.85483871, 0.14516129],\n",
              "       [0.14754098, 0.85245902],\n",
              "       [0.01775148, 0.98224852],\n",
              "       [0.05913978, 0.94086022],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.91176471, 0.08823529],\n",
              "       [0.        , 1.        ],\n",
              "       [0.45856354, 0.54143646],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.89119171, 0.10880829],\n",
              "       [0.02531646, 0.97468354],\n",
              "       [0.26395939, 0.73604061],\n",
              "       [0.60655738, 0.39344262],\n",
              "       [0.46733668, 0.53266332],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.63276836, 0.36723164],\n",
              "       [0.01104972, 0.98895028],\n",
              "       [0.28358209, 0.71641791],\n",
              "       [0.078125  , 0.921875  ],\n",
              "       [0.83783784, 0.16216216],\n",
              "       [1.        , 0.        ],\n",
              "       [0.8253012 , 0.1746988 ],\n",
              "       [0.42021277, 0.57978723],\n",
              "       [0.72463768, 0.27536232],\n",
              "       [0.99479167, 0.00520833],\n",
              "       [1.        , 0.        ],\n",
              "       [0.12138728, 0.87861272],\n",
              "       [0.17910448, 0.82089552],\n",
              "       [0.        , 1.        ],\n",
              "       [0.37172775, 0.62827225],\n",
              "       [0.98876404, 0.01123596],\n",
              "       [0.99014778, 0.00985222],\n",
              "       [0.81564246, 0.18435754],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.01123596, 0.98876404],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.24226804, 0.75773196],\n",
              "       [0.        , 1.        ],\n",
              "       [0.38797814, 0.61202186],\n",
              "       [0.02857143, 0.97142857],\n",
              "       [0.59340659, 0.40659341],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98924731, 0.01075269],\n",
              "       [0.68586387, 0.31413613],\n",
              "       [0.20744681, 0.79255319],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98907104, 0.01092896],\n",
              "       [0.98901099, 0.01098901],\n",
              "       [0.94300518, 0.05699482],\n",
              "       [0.        , 1.        ],\n",
              "       [0.03296703, 0.96703297],\n",
              "       [0.01546392, 0.98453608],\n",
              "       [1.        , 0.        ],\n",
              "       [0.94923858, 0.05076142],\n",
              "       [0.00561798, 0.99438202],\n",
              "       [0.03910615, 0.96089385],\n",
              "       [0.96571429, 0.03428571],\n",
              "       [0.94174757, 0.05825243],\n",
              "       [1.        , 0.        ],\n",
              "       [0.99450549, 0.00549451],\n",
              "       [0.94413408, 0.05586592],\n",
              "       [0.59259259, 0.40740741],\n",
              "       [0.79754601, 0.20245399],\n",
              "       [0.83589744, 0.16410256],\n",
              "       [0.09424084, 0.90575916],\n",
              "       [1.        , 0.        ],\n",
              "       [0.97409326, 0.02590674],\n",
              "       [0.45652174, 0.54347826],\n",
              "       [1.        , 0.        ],\n",
              "       [0.95      , 0.05      ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.21910112, 0.78089888],\n",
              "       [0.        , 1.        ],\n",
              "       [0.9947644 , 0.0052356 ],\n",
              "       [0.03351955, 0.96648045],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98876404, 0.01123596],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.76216216, 0.23783784],\n",
              "       [1.        , 0.        ],\n",
              "       [0.12972973, 0.87027027],\n",
              "       [0.13872832, 0.86127168],\n",
              "       [0.        , 1.        ],\n",
              "       [0.01630435, 0.98369565],\n",
              "       [1.        , 0.        ],\n",
              "       [0.67027027, 0.32972973],\n",
              "       [0.92820513, 0.07179487],\n",
              "       [0.        , 1.        ],\n",
              "       [0.7979798 , 0.2020202 ],\n",
              "       [0.93010753, 0.06989247],\n",
              "       [1.        , 0.        ],\n",
              "       [0.33870968, 0.66129032],\n",
              "       [0.92485549, 0.07514451],\n",
              "       [0.43502825, 0.56497175],\n",
              "       [0.04733728, 0.95266272],\n",
              "       [0.61666667, 0.38333333],\n",
              "       [0.9744898 , 0.0255102 ],\n",
              "       [0.04191617, 0.95808383],\n",
              "       [1.        , 0.        ],\n",
              "       [0.72251309, 0.27748691],\n",
              "       [0.01595745, 0.98404255],\n",
              "       [0.98974359, 0.01025641],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01015228, 0.98984772],\n",
              "       [0.9025641 , 0.0974359 ],\n",
              "       [0.20212766, 0.79787234],\n",
              "       [0.15384615, 0.84615385],\n",
              "       [0.4248366 , 0.5751634 ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00571429, 0.99428571],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.3968254 , 0.6031746 ],\n",
              "       [0.85279188, 0.14720812],\n",
              "       [0.95604396, 0.04395604],\n",
              "       [1.        , 0.        ],\n",
              "       [0.046875  , 0.953125  ],\n",
              "       [0.06285714, 0.93714286],\n",
              "       [1.        , 0.        ],\n",
              "       [0.08139535, 0.91860465],\n",
              "       [0.10309278, 0.89690722],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.05555556, 0.94444444],\n",
              "       [0.87777778, 0.12222222],\n",
              "       [0.14659686, 0.85340314],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.87640449, 0.12359551],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.70430108, 0.29569892],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.12820513, 0.87179487],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00558659, 0.99441341],\n",
              "       [0.        , 1.        ],\n",
              "       [0.01851852, 0.98148148],\n",
              "       [0.00497512, 0.99502488],\n",
              "       [0.03508772, 0.96491228],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.96153846, 0.03846154],\n",
              "       [0.0245098 , 0.9754902 ],\n",
              "       [0.73595506, 0.26404494],\n",
              "       [0.68421053, 0.31578947],\n",
              "       [0.8989899 , 0.1010101 ],\n",
              "       [0.27272727, 0.72727273],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.06842105, 0.93157895],\n",
              "       [0.71502591, 0.28497409],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.57425743, 0.42574257],\n",
              "       [0.01554404, 0.98445596],\n",
              "       [0.02941176, 0.97058824],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.99479167, 0.00520833],\n",
              "       [0.05076142, 0.94923858],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.87700535, 0.12299465],\n",
              "       [0.96987952, 0.03012048],\n",
              "       [1.        , 0.        ],\n",
              "       [0.18817204, 0.81182796],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.95530726, 0.04469274],\n",
              "       [0.        , 1.        ],\n",
              "       [0.10869565, 0.89130435],\n",
              "       [0.98404255, 0.01595745],\n",
              "       [0.9375    , 0.0625    ],\n",
              "       [0.315     , 0.685     ],\n",
              "       [0.34269663, 0.65730337],\n",
              "       [0.95882353, 0.04117647],\n",
              "       [1.        , 0.        ],\n",
              "       [0.9281768 , 0.0718232 ],\n",
              "       [0.57386364, 0.42613636],\n",
              "       [0.99418605, 0.00581395],\n",
              "       [0.68393782, 0.31606218],\n",
              "       [0.99484536, 0.00515464],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01162791, 0.98837209],\n",
              "       [0.00526316, 0.99473684],\n",
              "       [0.96045198, 0.03954802],\n",
              "       [0.01657459, 0.98342541],\n",
              "       [1.        , 0.        ],\n",
              "       [0.99431818, 0.00568182],\n",
              "       [1.        , 0.        ],\n",
              "       [0.2       , 0.8       ],\n",
              "       [0.01704545, 0.98295455],\n",
              "       [0.9726776 , 0.0273224 ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.925     , 0.075     ],\n",
              "       [0.03664921, 0.96335079],\n",
              "       [0.04624277, 0.95375723],\n",
              "       [0.06010929, 0.93989071],\n",
              "       [1.        , 0.        ],\n",
              "       [0.74175824, 0.25824176],\n",
              "       [0.07      , 0.93      ],\n",
              "       [0.01630435, 0.98369565],\n",
              "       [0.35233161, 0.64766839],\n",
              "       [0.98295455, 0.01704545],\n",
              "       [0.46486486, 0.53513514],\n",
              "       [0.98089172, 0.01910828],\n",
              "       [1.        , 0.        ],\n",
              "       [0.05487805, 0.94512195],\n",
              "       [0.13297872, 0.86702128],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.05369128, 0.94630872],\n",
              "       [0.02645503, 0.97354497],\n",
              "       [0.85405405, 0.14594595],\n",
              "       [0.01111111, 0.98888889],\n",
              "       [0.04444444, 0.95555556],\n",
              "       [0.        , 1.        ],\n",
              "       [0.05607477, 0.94392523],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99425287, 0.00574713],\n",
              "       [0.99421965, 0.00578035],\n",
              "       [0.91935484, 0.08064516],\n",
              "       [0.02247191, 0.97752809],\n",
              "       [1.        , 0.        ],\n",
              "       [0.76190476, 0.23809524],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00543478, 0.99456522],\n",
              "       [0.97159091, 0.02840909],\n",
              "       [1.        , 0.        ],\n",
              "       [0.05472637, 0.94527363],\n",
              "       [0.00520833, 0.99479167],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.84924623, 0.15075377],\n",
              "       [0.86842105, 0.13157895],\n",
              "       [1.        , 0.        ],\n",
              "       [0.13756614, 0.86243386],\n",
              "       [0.66666667, 0.33333333],\n",
              "       [0.        , 1.        ],\n",
              "       [0.29651163, 0.70348837],\n",
              "       [0.97969543, 0.02030457],\n",
              "       [0.00546448, 0.99453552],\n",
              "       [0.        , 1.        ],\n",
              "       [0.07389163, 0.92610837],\n",
              "       [0.11173184, 0.88826816],\n",
              "       [0.17714286, 0.82285714],\n",
              "       [0.0060241 , 0.9939759 ],\n",
              "       [0.10555556, 0.89444444],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01092896, 0.98907104],\n",
              "       [0.03351955, 0.96648045],\n",
              "       [0.08064516, 0.91935484],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.9027027 , 0.0972973 ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.96174863, 0.03825137],\n",
              "       [0.01025641, 0.98974359],\n",
              "       [0.05347594, 0.94652406],\n",
              "       [0.1352657 , 0.8647343 ],\n",
              "       [0.87765957, 0.12234043],\n",
              "       [0.        , 1.        ],\n",
              "       [0.75151515, 0.24848485],\n",
              "       [0.06565657, 0.93434343],\n",
              "       [1.        , 0.        ],\n",
              "       [0.05847953, 0.94152047],\n",
              "       [0.01075269, 0.98924731],\n",
              "       [0.03092784, 0.96907216],\n",
              "       [0.44505495, 0.55494505],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.35751295, 0.64248705],\n",
              "       [1.        , 0.        ],\n",
              "       [0.37810945, 0.62189055],\n",
              "       [0.97674419, 0.02325581],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.42424242, 0.57575758],\n",
              "       [0.62032086, 0.37967914],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.93782383, 0.06217617],\n",
              "       [1.        , 0.        ],\n",
              "       [0.06077348, 0.93922652],\n",
              "       [0.6978022 , 0.3021978 ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00606061, 0.99393939],\n",
              "       [0.42331288, 0.57668712],\n",
              "       [0.99450549, 0.00549451],\n",
              "       [0.21875   , 0.78125   ],\n",
              "       [0.02673797, 0.97326203],\n",
              "       [0.99444444, 0.00555556],\n",
              "       [1.        , 0.        ],\n",
              "       [0.97727273, 0.02272727],\n",
              "       [0.96315789, 0.03684211],\n",
              "       [0.53333333, 0.46666667],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.0049505 , 0.9950495 ],\n",
              "       [0.84357542, 0.15642458],\n",
              "       [0.00546448, 0.99453552],\n",
              "       [0.01111111, 0.98888889],\n",
              "       [0.01666667, 0.98333333],\n",
              "       [0.96354167, 0.03645833],\n",
              "       [0.97790055, 0.02209945],\n",
              "       [0.97326203, 0.02673797],\n",
              "       [0.00985222, 0.99014778],\n",
              "       [1.        , 0.        ],\n",
              "       [0.37894737, 0.62105263],\n",
              "       [0.23414634, 0.76585366],\n",
              "       [0.86263736, 0.13736264],\n",
              "       [0.        , 1.        ],\n",
              "       [0.11052632, 0.88947368],\n",
              "       [0.32795699, 0.67204301],\n",
              "       [0.        , 1.        ],\n",
              "       [0.84117647, 0.15882353],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.05978261, 0.94021739],\n",
              "       [0.99371069, 0.00628931],\n",
              "       [0.        , 1.        ],\n",
              "       [0.96954315, 0.03045685],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98351648, 0.01648352]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3 랜덤 패치와 랜덤 서브스페이스\n",
        "- 특성 샘플링 지원\n",
        "- max_features, bootstrap_features 두 매개변수로 조절\n",
        "- 특성에 대한 샘플링(각 예측기는 무작위로 선택한 입력 특성의 일부분으로 훈련)\n",
        "- 고차원 데이터셋 다룰 때 유용\n",
        "- 랜덤 패치 방식: 훈련 특성과 샘플을 모두 샘플링하는 것\n",
        "- 랜덤 서브스페이스 방식: 훈련 샘플 모두 사용(bootstrap=False,max_samples=1.0)/\n",
        " 특성은 샘플링(bootstrap_features=True, max_features<1)\n",
        "\n",
        " - 특성 샘플링은 더 다양한 예측기를 만들며 편향을 늘리는 대신 분산 낮춤"
      ],
      "metadata": {
        "id": "2jEAa4jFU4Fr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.4 랜덤포레스트\n",
        "- 배깅(또는 페이스팅) 방법을 적용한 결정 트리의 앙상블\n",
        "- 트리의 노드를 분할할 때 전체 특성 중에서 최선의 특성을 찾는 대신 무작위로 선택해 특성 후보 중에서 최적의 특성을 찾는 식으로 무작위성 주입\n",
        " -> 트리 다양, 편향 손해 대신 분산 낮춰 더 훌륭한 모델"
      ],
      "metadata": {
        "id": "oMyn7rUxcz0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf=RandomForestClassifier(n_estimators=500,max_leaf_nodes=16,n_jobs=-1)\n",
        "rnd_clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred_rf=rnd_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "9SQOnowB9GBX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#랜덤포레스트와 유사\n",
        "bag_clf=BaggingClassifier(\n",
        "    DecisionTreeClassifier(max_features=\"auto\",max_leaf_nodes=16),\n",
        "    n_estimators=500,max_samples=1.0,bootstrap=True,n_jobs=-1)"
      ],
      "metadata": {
        "id": "_mCvKPXD9F-g"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4.1 엑스트라 트리\n",
        "- 랜덤포레스트에서 트리를 만들 때 각 노드는 무작위로 특성의 서브셋을 만들어 분할에 사용\n",
        "- 익스트림 랜덤 트리 앙상블: 트리를 더 무작위하게 만들기 위해 후보 특성을 사용해 무작위로 분할 후 최상의 분할 선택\n",
        "  - 편향이 늘어나지만 분산 낮추게 됨\n",
        "  - 모든 노드에서 특성마다 가장 최적의 임곗값을 찾는 것이 트리 알고리즘에서 가장 시간이 많이 소요됨>랜덤 포레스트보다 훨씬 빠름"
      ],
      "metadata": {
        "id": "03RYrfAre1jj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4.2 특성 중요도\n",
        "- 특성의 상대적 중요도 측정 쉬움\n",
        "- 사이킷런\n",
        "  - 어떤 특성을 사용한 노드가 평균적으로 불순도를 얼마나 감소시키는지 확인하여 특성의 중요도 측정(가중치 평균)\n",
        "  - 훈련이 끝난 뒤 특성마다 자동으로 점수 계사, 중요도의 전체 합이 1이 되도록 결괏값 정규화 -->feature_importances \n"
      ],
      "metadata": {
        "id": "T5iihlKciCsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris=load_iris()\n",
        "rnd_clf=RandomForestClassifier(n_estimators=500,n_jobs=-1)\n",
        "rnd_clf.fit(iris[\"data\"],iris[\"target\"])\n",
        "for name,score in zip(iris[\"feature_names\"],rnd_clf.feature_importances_):\n",
        "  print(name,score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gdjwRAA9F7x",
        "outputId": "1710107c-ae59-437e-d509-40645d90d317"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm) 0.09194511308991098\n",
            "sepal width (cm) 0.023513792972713058\n",
            "petal length (cm) 0.4208869042321851\n",
            "petal width (cm) 0.463654189705191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.5 부스팅\n",
        "- 약한 학습기 여러개 연결하여 강한 학습기를 만드는 앙상블 방법\n",
        "- 앞의 모델 보완해나가며 일련의 예측기 학습시키는 것"
      ],
      "metadata": {
        "id": "C1V-iqVpjNd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.5.1 에이다부스트\n",
        "- 이전 모델이 과소적합했던 훈련 샘플의 가중치를 더 높이는 것\n",
        "- 경사하강법과 비슷\n",
        "- 사이킷런: 클래스 확률에 기반"
      ],
      "metadata": {
        "id": "Zdx9KAGtjlBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#max_depth=1: 결정 노드 하나와 리프 노드 두개로 이루어짐\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ada_clf=AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1),n_estimators=200,\n",
        "    algorithm=\"SAMME.R\",learning_rate=0.5)\n",
        "ada_clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjrn7QQbjNDh",
        "outputId": "d626ef42-0614-462c-d668-98d25d35c8d3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
              "                   learning_rate=0.5, n_estimators=200)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.5.2 그레이디언트 부스팅\n",
        "- 앙상블에 이전까지의 오차를 보정하도록 예측기를 순차적으로 추가\n",
        "- 이전 예측기가 만든 잔여 오차에 새로운 예측기 학습\n",
        "\n",
        "\n",
        "- learning_rate: 각 트리의 기여 정도 조절\n",
        "  - 낮게 설정) 많은 트리 필요, 일반적으로 예측 성능 좋음 --- \"축소\"\n",
        "- 최적의 트리 수를 찾기 위해 조기 종료 기법 사용; staged_predicted()\n",
        "\n",
        "\n",
        "- 확률적 그레이디언트 부스팅: 훈련 샘플을 적게 설정하면, 편향 높 분산 낮/훈련 속도를 상당히 높\n"
      ],
      "metadata": {
        "id": "PWTVoQLplQli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#첫번째 예측기\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1=DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg1.fit(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6i0_-VO9F46",
        "outputId": "9bd1c97e-39b8-4d52-9992-2dcc723e292d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#두번째 예측기\n",
        "y2=y-tree_reg1.predict(X)\n",
        "tree_reg2=DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg2.fit(X,y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wwK7KGx9F2M",
        "outputId": "70b8c0f3-bde4-4a82-b207-48b92b7af14e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#세번째 예측기\n",
        "y3=y2-tree_reg2.predict(X)\n",
        "tree_reg3=DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg3.fit(X,y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3FzKvAV9Fz-",
        "outputId": "0166c00f-dab2-4d65-c0bc-6e1ff8c5d892"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=sum(tree.predict(X_new) for tree in (tree_reg1,tree_reg2,tree_reg3))"
      ],
      "metadata": {
        "id": "_FOcvah4mWJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "gbrt=GradientBoostingRegressor(max_depth=2,n_estimators=3,learning_rate=1)\n",
        "gbrt.fit(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_f2mynumdyN",
        "outputId": "2cf21b69-8a0d-470c-bf56-fd08c1826f50"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(learning_rate=1, max_depth=2, n_estimators=3)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train,X_val,y_train,y_val=train_test_split(X,y)\n",
        "\n",
        "gbrt=GradientBoostingRegressor(max_depth=2,n_estimators=120)\n",
        "gbrt.fit(X_train,y_train)\n",
        "\n",
        "errors=[mean_squared_error(y_val,y_pred)\n",
        "        for y_pred in gbrt.staged_predict(X_val)]\n",
        "bst_n_estimators=np.argmin(errors)+1\n",
        "\n",
        "gbrt_best=GradientBoostingRegressor(max_depth=2,n_estimators=bst_n_estimators)\n",
        "gbrt_best.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRlbT-DTmdvH",
        "outputId": "955d5512-b4b4-41eb-fad7-af2cbcbc0694"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(max_depth=2, n_estimators=51)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#warm_start=True : 훈련 추가\n",
        "gbrt=GradientBoostingRegressor(max_depth=2,warm_start=True)\n",
        "\n",
        "min_val_error=float(\"inf\")\n",
        "error_going_up=0\n",
        "for n_estimators in range(1,120):\n",
        "  gbrt.n_estimators=n_estimators\n",
        "  gbrt.fit(X_train,y_train)\n",
        "  y_pred=gbrt.predict(X_val)\n",
        "  val_error=mean_squared_error(y_val,y_pred)\n",
        "  if val_error < min_val_error:\n",
        "    min_val_error=val_error\n",
        "    error_going_up=0\n",
        "  else:\n",
        "    error_going_up+=1\n",
        "    if error_going_up==5:\n",
        "      break"
      ],
      "metadata": {
        "id": "4E0SkUJmmdsd"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#최적화된 그레이디언트 부수팅 구현으로 XGBoost 파이썬 라이브러리 유명\n",
        "import xgboost\n",
        "\n",
        "xgb_reg=xgboost.XGBRegressor()\n",
        "xgb_reg.fit(X_train,y_train)\n",
        "y_pred=xgb_reg.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oM_e7Npmdp9",
        "outputId": "247db8bb-2163-43f1-96c2-3703d3950163"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:43:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#자동 조기 종료\n",
        "xgb_reg.fit(X_train,y_train,eval_set=[(X_val,y_val)],early_stopping_rounds=2)\n",
        "y_pred=xgb_reg.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS4OPxwCmdn8",
        "outputId": "8f83f5c1-d6d4-4c24-c6bd-ee1f0fe920e2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:45:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:0.470711\n",
            "Will train until validation_0-rmse hasn't improved in 2 rounds.\n",
            "[1]\tvalidation_0-rmse:0.446117\n",
            "[2]\tvalidation_0-rmse:0.426248\n",
            "[3]\tvalidation_0-rmse:0.409439\n",
            "[4]\tvalidation_0-rmse:0.393658\n",
            "[5]\tvalidation_0-rmse:0.380216\n",
            "[6]\tvalidation_0-rmse:0.37125\n",
            "[7]\tvalidation_0-rmse:0.362521\n",
            "[8]\tvalidation_0-rmse:0.355159\n",
            "[9]\tvalidation_0-rmse:0.35038\n",
            "[10]\tvalidation_0-rmse:0.344469\n",
            "[11]\tvalidation_0-rmse:0.341888\n",
            "[12]\tvalidation_0-rmse:0.337277\n",
            "[13]\tvalidation_0-rmse:0.334131\n",
            "[14]\tvalidation_0-rmse:0.333638\n",
            "[15]\tvalidation_0-rmse:0.33167\n",
            "[16]\tvalidation_0-rmse:0.331038\n",
            "[17]\tvalidation_0-rmse:0.326692\n",
            "[18]\tvalidation_0-rmse:0.323648\n",
            "[19]\tvalidation_0-rmse:0.324173\n",
            "[20]\tvalidation_0-rmse:0.321179\n",
            "[21]\tvalidation_0-rmse:0.320841\n",
            "[22]\tvalidation_0-rmse:0.320236\n",
            "[23]\tvalidation_0-rmse:0.320037\n",
            "[24]\tvalidation_0-rmse:0.318084\n",
            "[25]\tvalidation_0-rmse:0.31647\n",
            "[26]\tvalidation_0-rmse:0.316295\n",
            "[27]\tvalidation_0-rmse:0.316225\n",
            "[28]\tvalidation_0-rmse:0.316781\n",
            "[29]\tvalidation_0-rmse:0.315465\n",
            "[30]\tvalidation_0-rmse:0.316155\n",
            "[31]\tvalidation_0-rmse:0.315246\n",
            "[32]\tvalidation_0-rmse:0.315154\n",
            "[33]\tvalidation_0-rmse:0.315281\n",
            "[34]\tvalidation_0-rmse:0.315226\n",
            "Stopping. Best iteration:\n",
            "[32]\tvalidation_0-rmse:0.315154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 스태킹\n",
        "- 앙상블에 속한 모든 예츢의 예측을 취합하는 모델을 훈련시킬 수 없을까요?라는 기본 아이디어에서 출발\n",
        "- 블레더를 학습시키는 일반적인 방법은 홀드 아웃 세트 사용"
      ],
      "metadata": {
        "id": "c2ay5rxiuqMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ay655BN0mdip"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
