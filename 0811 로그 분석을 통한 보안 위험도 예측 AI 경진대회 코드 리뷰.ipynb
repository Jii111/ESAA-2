{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e7d23a",
   "metadata": {},
   "source": [
    "# **로그 분석을 통한 보안 위험도 예측 AI 경진대회**\n",
    "-Team SsulleBal\n",
    "https://dacon.io/competitions/official/235717/codeshare/2679?page=2&dtype=recent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c360a6e4",
   "metadata": {},
   "source": [
    "- 기존에 확인된 위험요소는 0-6의 위험도 분류, 새로운 위험 요소는 위험도 7로 분류\n",
    "- Level 7 구별\n",
    "\n",
    "\n",
    "- 로그 데이터 전처리 > Validation을 통해 등급별로 threshold 상세 설정\n",
    "- 실제 서비스에서 Line by Line으로 들어왔을 때의 분류방법:  \n",
    "  1) 로그 문장 데이터 전처리 진행 (Cleaning)  \n",
    "  2) train 데이터와 완전히 동일한 문장이 있는지 확인하여 서로 다른 모델 적용(A방법, B방법)  \n",
    "  -A방법: 동일한 문장이 있다면 0-6 등급 지도 학습된 모델로 Predict(Threshold 적용 X)  \n",
    "  -B방법: 동일한 문장이 없다면 0-6 등급 지도 학습된 모델로 Predict 이후에 설정된 Threshold 를 통해 7은 따로 분류  \n",
    "  3) B방법에서 Threshold를 통해 걸러지지 않는다면 A방법과 동일한 모델로 predict 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67441ad0",
   "metadata": {},
   "source": [
    "1> 로그 문장 데이터 전처리 진행(Cleaning)   \n",
    "\n",
    "2> CountVectorizer로 feature 추출 > RandomForestClassifier\n",
    "- train 데이터와 동일한 문장이 있다면, 0-6 등급 지도 학습된 모델로 Predict\n",
    "- 전처리 덜 된 데이터로 모델 생성\n",
    "- 동일한 문장이 없다면, 모델 Predict 후 Validation 데이터로 설정한 Threshold를 통해 위험도 7 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123bae4",
   "metadata": {},
   "source": [
    "### **1. Data&Library IMPORT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fba641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EnvironmentNotWritableError: The current user does not have write permissions to the target environment.\n",
      "  environment location: C:\\ProgramData\\Anaconda3\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  environment location: C:\\ProgramData\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - dask\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.13.0               |   py38haa95532_0         926 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         926 KB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda              conda-forge::conda-4.10.3-py38haa244f~ --> pkgs/main::conda-4.13.0-py38haa95532_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "conda-4.13.0         | 926 KB    |            |   0% \n",
      "conda-4.13.0         | 926 KB    | #5         |  16% \n",
      "conda-4.13.0         | 926 KB    | ########4  |  85% \n",
      "conda-4.13.0         | 926 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... failed\n"
     ]
    }
   ],
   "source": [
    "conda install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8631d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pds\n",
    "from dask import dataframe\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sbn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a502640",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test= pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ba4958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "      <th>full_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sep 24 10:02:22 localhost kibana: {\"type\":\"err...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Feb  8 16:21:00 localhost logstash: [2021-02-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan 13 01:50:40 localhost kibana: {\"type\":\"err...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan  4 10:18:31 localhost kibana: {\"type\":\"err...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>type=SYSCALL msg=audit(1603094402.016:52981): ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  level                                           full_log\n",
       "0   0      0  Sep 24 10:02:22 localhost kibana: {\"type\":\"err...\n",
       "1   1      0  Feb  8 16:21:00 localhost logstash: [2021-02-0...\n",
       "2   2      0  Jan 13 01:50:40 localhost kibana: {\"type\":\"err...\n",
       "3   3      0  Jan  4 10:18:31 localhost kibana: {\"type\":\"err...\n",
       "4   4      1  type=SYSCALL msg=audit(1603094402.016:52981): ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3428303a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>Feb  8 15:47:26 localhost kibana: {\"type\":\"err...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>Sep 24 03:46:39 localhost kibana: {\"type\":\"err...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000002</td>\n",
       "      <td>type=SYSCALL msg=audit(1611888200.428:210563):...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000003</td>\n",
       "      <td>Jan 18 11:24:06 localhost kibana: {\"type\":\"err...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000004</td>\n",
       "      <td>type=SYSCALL msg=audit(1603081202.050:46851): ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           full_log\n",
       "0  1000000  Feb  8 15:47:26 localhost kibana: {\"type\":\"err...\n",
       "1  1000001  Sep 24 03:46:39 localhost kibana: {\"type\":\"err...\n",
       "2  1000002  type=SYSCALL msg=audit(1611888200.428:210563):...\n",
       "3  1000003  Jan 18 11:24:06 localhost kibana: {\"type\":\"err...\n",
       "4  1000004  type=SYSCALL msg=audit(1603081202.050:46851): ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "278ef4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1418916"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322faa8e",
   "metadata": {},
   "source": [
    "### **2. EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3118e8d",
   "metadata": {},
   "source": [
    "1) 기호 및 숫자 제거\n",
    "- re.sub(정규표현식,'',변경하고 싶은 문자): 정규식을 이용해 특정 길이 단어 제거\n",
    "- '\\s' : 띄어쓰기, 탭, 줄바꿈 같은 공간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f4138b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "\n",
    "def mask(tt):\n",
    "    tt=tt.apply(lambda x: re.sub(r'(\\\\n)',' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r'[^a-zA-Zㄱ-ㅣ가-힣0-9:=\\s\\(\\)./,\\<\\>]+',' ',x))\n",
    "    #tt=tt.apply(lambda x: re.sub(r' ?(?P<note>[:=\\(\\)./,\\<\\>]) ?', ' \\g<note> ', x))\n",
    "    tt=tt.apply(lambda x: re.sub(r'[0-9]+',' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r\"':/()\",' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r':',' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r',',' ',x))\n",
    "    # = tt.apply(lambda x: re.sub(r'(',' ',x))\n",
    "    #t = tt.apply(lambda x: re.sub(r')',' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]',' ',x))\n",
    "    \n",
    "    for st in lit:\n",
    "        st = \" \"+ st + \" \"\n",
    "        tt=tt.apply(lambda x: re.sub(st,' ',x))\n",
    "        \n",
    "    tt=tt.apply(lambda x: re.sub(r'\\s+',' ',x))\n",
    "    \n",
    "    return tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d8c20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pre_log'] = mask(train.full_log)\n",
    "test['pre_log'] = mask(test.full_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc34cef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "      <th>full_log</th>\n",
       "      <th>pre_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sep 24 10:02:22 localhost kibana: {\"type\":\"err...</td>\n",
       "      <td>Sep localhost kibana type error timestamp tags...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Feb  8 16:21:00 localhost logstash: [2021-02-0...</td>\n",
       "      <td>Feb localhost logstash INFO logstash outputs e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan 13 01:50:40 localhost kibana: {\"type\":\"err...</td>\n",
       "      <td>Jan localhost kibana type error timestamp tags...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan  4 10:18:31 localhost kibana: {\"type\":\"err...</td>\n",
       "      <td>Jan localhost kibana type error timestamp tags...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>type=SYSCALL msg=audit(1603094402.016:52981): ...</td>\n",
       "      <td>type SYSCALL msg audit arch syscall success ye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  level                                           full_log  \\\n",
       "0   0      0  Sep 24 10:02:22 localhost kibana: {\"type\":\"err...   \n",
       "1   1      0  Feb  8 16:21:00 localhost logstash: [2021-02-0...   \n",
       "2   2      0  Jan 13 01:50:40 localhost kibana: {\"type\":\"err...   \n",
       "3   3      0  Jan  4 10:18:31 localhost kibana: {\"type\":\"err...   \n",
       "4   4      1  type=SYSCALL msg=audit(1603094402.016:52981): ...   \n",
       "\n",
       "                                             pre_log  \n",
       "0  Sep localhost kibana type error timestamp tags...  \n",
       "1  Feb localhost logstash INFO logstash outputs e...  \n",
       "2  Jan localhost kibana type error timestamp tags...  \n",
       "3  Jan localhost kibana type error timestamp tags...  \n",
       "4  type SYSCALL msg audit arch syscall success ye...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d20001c",
   "metadata": {},
   "source": [
    "2) 영어 단어가 아니거나 3글자 미만인 경우 삭제\n",
    "- Validation 7등급을 보았을 때, 의미가 있는 영어 단어들이 새로 들어오는 경향이 있다고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25a67bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#포함되어 있는 단어 모음 생성\n",
    "def count_word(data):\n",
    "    tem = list(data['pre_log'].str.split(\" \"))\n",
    "    all_word = []\n",
    "    for word in tem:\n",
    "        all_word.extend(word)\n",
    "    words = pd.Series(all_word)\n",
    "    return words.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "921c9793",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = count_word(train)\n",
    "test_count = count_word(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7820cd",
   "metadata": {},
   "source": [
    "- set: 집합  \n",
    "    -중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b15e8f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = list(set(train_count.index))\n",
    "test_words = list(set(test_count.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88847216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#영어 단어 + 3글자 이상인 경우만 True\n",
    "#check_words는 단어인지를 확인해주고 결과를 t/f로 반환\n",
    "\n",
    "from nltk.corpus import words\n",
    "\n",
    "def check_words(word_list: list):\n",
    "    re = [False] * len(word_list)\n",
    "    \n",
    "    for i,word in enumerate(word_list):\n",
    "        if len(word) < 3:\n",
    "            continue\n",
    "        word = word.lower()\n",
    "        if word in words.words():\n",
    "            re[i] = True\n",
    "            \n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b42153ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False, True, False, True]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = ['Promiscuous', 'ab', 'nihongo', 'abstract', 'pedo','gid']\n",
    "check_words(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e241c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = check_words(train_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4da6d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tf = check_words(test_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a552ae4",
   "metadata": {},
   "source": [
    "- train_words: 포함되어 있는 단어 모음    \n",
    "  train_tf=check_words(train_words) T/F  \n",
    "  dic[train_words]=train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2624663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어인지 확인해주는 딕셔너리 만들어주기 (train_isword,test_isword)\n",
    "train_isword = dict()\n",
    "test_isword = dict()\n",
    "\n",
    "total_words = list(train_words)\n",
    "test_words = list(test_words)\n",
    "\n",
    "for i in range(len(train_words)):\n",
    "    train_isword[train_words[i].lower()] = train_tf[i]\n",
    "    \n",
    "for i in range(len(test_words)):\n",
    "    test_isword[test_words[i].lower()] = test_tf[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa456d8",
   "metadata": {},
   "source": [
    "3) Train, Test에 각각 적용\n",
    "- 미리 사용된 단어들을 모아서 딕셔너리를 만들어서 사용하며 시간 단축\n",
    "- Data Leakage 가능성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55740eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어를 하나씩 확인하는 방법(60~70 시간 이상 소요) \n",
    "from nltk.corpus import words \n",
    "\n",
    "def check_words(word_list: list): \n",
    "    re = [False] * len(word_list) \n",
    "    for i,word in enumerate(word_list): \n",
    "        word = word.lower() \n",
    "        if len(word)>2: \n",
    "            if word in words.words(): \n",
    "                re[i] = True \n",
    "    return re\n",
    "\n",
    "def cutt(data): \n",
    "    data = data.lower() \n",
    "    splited = data.split(\" \") \n",
    "    check = check_words(splited) \n",
    "    c = np.array(splited) \n",
    "    real_words = list(c[check]) \n",
    "    tem = \" \".join(real_words) \n",
    "    return tem\n",
    "\n",
    "#valid['cut'] = valid['pre_log'].map(cutt) \n",
    "#train['cut'] =train['pre_log'].map(cutt) \n",
    "#test['cut'] =test['pre_log'].map(cutt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b3d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def checking_train(data):\n",
    "    re = [False] * len(data)\n",
    "    for i,word in enumerate(data):\n",
    "        if train_isword[word]:\n",
    "            re[i] = True\n",
    "    return re\n",
    "\n",
    "def checking_test(data):\n",
    "    re = [False] * len(data)\n",
    "    for i,word in enumerate(data):\n",
    "        if test_isword[word]:\n",
    "            re[i] = True\n",
    "    return re\n",
    "\n",
    "def cutt_train(data):\n",
    "    data = data.lower()\n",
    "    splited = data.split(\" \")\n",
    "    check = checking_train(splited)\n",
    "    c = np.array(splited)\n",
    "    real_words = list(c[check])    \n",
    "    tem = \" \".join(real_words)\n",
    "    #tem = tem.lower() \n",
    "    return tem\n",
    "\n",
    "def cutt_test(data):\n",
    "    data = data.lower()\n",
    "    splited = data.split(\" \")\n",
    "    check = checking_test(splited)\n",
    "    c = np.array(splited)\n",
    "    real_words = list(c[check])  \n",
    "    tem = \" \".join(real_words)\n",
    "    #tem = tem.lower()\n",
    "    return tem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9c575b",
   "metadata": {},
   "source": [
    "- map 함수 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bafc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cut'] = train['pre_log'].map(cutt_train)\n",
    "test['cut'] = test['pre_log'].map(cutt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a379a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['full_log']\n",
    "del test['full_log']\n",
    "\n",
    "del train['pre_log']\n",
    "del test['pre_log']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee048d",
   "metadata": {},
   "source": [
    "4) 나중에 사용될 inornot 리스트\n",
    "- train 데이터에 100% 동일한 문장이 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b07ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag = train['cut'].unique()\n",
    "len(train_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d737e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inornot을 통해서 train안에 같은 문장이 있으면 0 없으면 1\n",
    "from tqdm import tqdm\n",
    "\n",
    "inornot = np.zeros(len(test))\n",
    "\n",
    "for i in tqdm(range(len(test))):\n",
    "    tem = test.iloc[i]['cut']\n",
    "    if tem not in train_bag:\n",
    "        inornot[i] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9dd8b3",
   "metadata": {},
   "source": [
    "### **3. 모델링**\n",
    "- CountVectorizer: 각 문서에서 해당 단어가 나타나는 횟수를 Count하여 피처로 사용  \n",
    "→ train/test_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8311222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#남은 단어가 없는 경우에는 'missing' 으로 대체\n",
    "train['cut'] = train['cut'].replace('','missing',regex=True)\n",
    "test['cut'] = test['cut'].replace('','missing',regex=True)\n",
    "\n",
    "train = train.fillna(\"missing\")\n",
    "test = test.fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401657fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text=list(train['cut'])\n",
    "train_level=np.array(train['level'])\n",
    "\n",
    "test_text=list(test['cut'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094845cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(analyzer=\"word\", max_features=20000)\n",
    "train_features=vectorizer.fit_transform(train_text)\n",
    "test_features=vectorizer.transform(test_text)- RandomForestClassifier 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f965043c",
   "metadata": {},
   "source": [
    "- RandomForestClassifier 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f19a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest=RandomForestClassifier(n_estimators=100,random_state = 1 )\n",
    "forest.fit(train_features,train_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=forest.predict(test_features)\n",
    "results_proba=forest.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b404de9",
   "metadata": {},
   "source": [
    "- Validation을 이용해 위험도 7 분류  \n",
    "\n",
    "1) 모델 학습 후 test셋 예측  \n",
    "2) test에서 유추할 수 있는 level7의 예측확률 확인  \n",
    "3) 예측확률에 맞게 threshold 조정 ( [0.37<preds<0.3876] = level7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation을 통한 threshold 조절\n",
    "results[np.where((np.max(results_proba, axis=1)<0.5) & (results == 0))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.5) & (results == 1))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.58) & (results == 2))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.95) & (results == 3))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.58) & (results == 4))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.58) & (results == 5))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.58) & (results == 6))[0]]=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212db6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation을 통한 threshold 조절\n",
    "results[np.where((np.max(results_proba, axis=1)<0.94001) & (np.max(results_proba, axis=1) > 0.93999) & (results == 1))[0]]=7 \n",
    "results[np.where((np.max(results_proba, axis=1)<0.611657) & (np.max(results_proba, axis=1) > 0.6116568) & (results == 0))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.571657) & (np.max(results_proba, axis=1) > 0.5716568) & (results == 0))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.68001) & (np.max(results_proba, axis=1) > 0.67999) & (results == 5))[0]]=7 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2902f991",
   "metadata": {},
   "source": [
    "### **4. 결과 저장**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a92c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.read_csv('sample_submission.csv')\n",
    "submission['level']=results\n",
    "submission['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28b0d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"tem_answer.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb7f750",
   "metadata": {},
   "source": [
    "### **5. 추가 작업**\n",
    "- test 데이터에 동일한 문장이 있는지 확인하는 컬럼 추가\n",
    "- 같은 문장이 있으면 0 없으면 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['inornot'] = pd.Series(inornot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f014af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = submission[(submission['level']==7) & (submission['inornot'] == 0)].index #위험도 7 & 같은 문장 있는 경우\n",
    "not7_id = list(test.iloc[cal]['id'])\n",
    "pd.Series(not7_id).to_csv(\"not7_id.csv\",index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc583135",
   "metadata": {},
   "source": [
    "- 7를 제외한 나머지 등급에는 전처리가 덜 진행된 Data로 지도학습 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff655966",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['full_log']=train['full_log'].str.replace(r'[0-9]', '<num>')\n",
    "test['full_log']=test['full_log'].str.replace(r'[0-9]', '<num>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0958efa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(\"missing\")\n",
    "test = test.fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9329b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text=list(train['full_log'])\n",
    "train_level=np.array(train['level'])\n",
    "\n",
    "test_text=list(test['full_log'])\n",
    "#ids=list(test['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(analyzer=\"word\", max_features=20000)\n",
    "train_features=vectorizer.fit_transform(train_text)\n",
    "test_features=vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=forest.predict(test_features)\n",
    "results_proba=forest.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2039715",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.read_csv('sample_submission.csv')\n",
    "submission['level']=results\n",
    "submission['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2991bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "not7_id = pd.read_csv('not7_id.csv')\n",
    "not7_id = list(not7_id['0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83348e67",
   "metadata": {},
   "source": [
    "- 위에서 잡은 7 합치기 & train에 있는 경우는 사용하지 않기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fbf75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "only = pd.read_csv(\"tem_answer.csv\")\n",
    "\n",
    "le7 = list(only[only['level']==7]['id'])\n",
    "le7_update = list((set(le7))-set(not7_id))\n",
    "print(len(le7))\n",
    "print(len(le7_update))\n",
    "\n",
    "idx = submission[submission['id'].isin(le7_update)].index\n",
    "submission.iloc[idx] = 7\n",
    "submission['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83562c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "who = submission.level\n",
    "submission=pd.read_csv('sample_submission.csv')\n",
    "submission['level'] = who\n",
    "submission['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214c8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"581_final_answer.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
