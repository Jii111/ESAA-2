{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10주차 추천시스템.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOMua1f6xp43KDBHZENn983"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **파이썬 머신러닝 완벽가이드 ch9 pg. 562-579**"
      ],
      "metadata": {
        "id": "Fz3RtTVHpF6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **01. 추천시스템의 개요와 배경**\n",
        "- 추천시스템에 사용되는 데이터  \n",
        "  -구매한 상품  \n",
        "  -장바구니에 추가한 상품  \n",
        "  -평가한 영화 평점/제품 평가  \n",
        "  -스스로 작성한 자신의 취향  \n",
        "  -사용자가 클릭한 것  \n",
        "\n",
        "- 추천 시스템의 유형  \n",
        "  -콘텐츠 기반 필터링 방식  \n",
        "  -협업 필터링 방식  \n",
        "     - 최근접 이웃 협업 필터링  \n",
        "     - 잠재 요인 협업 필터링: 많이 사용\n",
        "\n",
        "- 개인화 특성을 좀 더 강화하기 위해 하이브리드 형식으로 콘텐츠 기반과 협업기반 적절히 결합해 사용"
      ],
      "metadata": {
        "id": "ds8H11zAp3uT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **02. 콘텐츠 기반 필터링 추천 시스템**\n",
        "- 선호하는 특정한 아이템과 비슷한 아이템 추천  \n",
        "(ex) 영화: 그 영화의 장르, 출연 배우, 감독, 영화 키워드 등의 콘텐츠와 유사한 다른 영화 추천"
      ],
      "metadata": {
        "id": "5xOyMCQ6sMWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **03. 최근접 이웃 협업 필터링**\n",
        "- 평점 정보, 상품 구매 이력 등 사용자 행동 양식만을 기반으로 추천 수행\n",
        "- 목표: 사용자-아이템 평점 매트릭스와 같은 축적된 사용자 행동 데이터를 기반으로 사용자가 아직 평가하지 않은 아이템을 예측 평가\n",
        "- 사용자-아이템 평점 매트릭스는 희소 행렬\n",
        "- **최근접 이웃 방식**(메모리 협업 필터링)\n",
        "  - 사용자 기반: 당신과 비슷한 고객들이 다음 상품도 구매했습니다.\n",
        "  - 아이템 기반: 이 상품을 선택한 다른 고객들은 다음 상품도 구매했습니다.  \n",
        "    -아이템의 속성과 상관없이 사용자들이 그 아이템을 좋아하는지/싫어하는지의 평가 척도가 유사한 아이템 추천\n",
        "  - 일반적으로 아이템 기반 협업 필터링이 정확도 더 높음\n",
        "  - 코사인 유사도 많이 사용\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y22K4HwFtanE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **04. 잠재 요인 협업 필터링**\n",
        "- 잠재 요인 추출해 추천 예측\n",
        "- 행렬 분해: 대규모 다차원 행렬을 SVD와 같은 차원 감소 기법으로 분해하는 과정에서 잠재 요인 추출\n",
        "- '잠재 요인'을 기반으로 사용자-아이템 행렬 데이터를 사용자-잠재요인 행렬/아이템-잠재요인 행렬의 전치 행렬로 분해\n",
        " -> 내적을 통해 새로운 예측 사용자-아이템 평점 행렬 데이터를 만들어서 사용자가 아직 평점을 부여하지 않은 아이템에 대한 예측 평점을 생성하는 것\n",
        "\n",
        "- **행렬 분해**  \n",
        "  -SVD, NMF 등의 방식 이용  \n",
        "  -주로 SVD 방식 이용하지만, NaN 값이 없는 행렬에만 적용할 수 있음  \n",
        "  -NaN값이 있다면, 확률적 경사 하강법(SGD) 이용해 SVD 수행\n",
        "    - P와 Q 행렬로 계산된 예측 R 행렬 값이 실제 R 행렬 값과 가장 최소의 오류를 가질 수 있도록 반복적인 비용 함수 최적화를 통해 P와 Q 유추\n",
        "\n"
      ],
      "metadata": {
        "id": "0n81PmWPxeAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#원본 행렬\n",
        "R=np.array([[4,np.NaN,np.NaN,2,np.NaN],\n",
        "            [np.NaN,5,np.NaN,3,1],\n",
        "            [np.NaN,np.NaN,3,4,4],\n",
        "            [5,2,1,2,np.NaN]])\n",
        "num_users,num_items=R.shape\n",
        "K=3\n",
        "\n",
        "np.random.seed(1)\n",
        "P=np.random.normal(scale=1./K,size=(num_users,K))\n",
        "Q=np.random.normal(scale=1./K,size=(num_items,K))"
      ],
      "metadata": {
        "id": "KhoM-OtApQRe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#실제 R 행렬과 예측 행렬의 오차행렬의 오차 구하기\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_rmse(R,P,Q,non_zeros):\n",
        "  error=0\n",
        "  full_pred_matrix=np.dot(P,Q.T)\n",
        "\n",
        "  x_non_zero_ind=[non_zero[0] for non_zero in non_zeros]\n",
        "  y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
        "  R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
        "  full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
        "      \n",
        "  mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
        "  rmse = np.sqrt(mse)\n",
        "    \n",
        "  return rmse"
      ],
      "metadata": {
        "id": "N-CFAPIYpQO1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD 기반으로 행렬분해 수행 \n",
        "non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]\n",
        "\n",
        "steps=10000\n",
        "learning_rate=0.01\n",
        "r_lambda=0.01\n",
        "\n",
        "# 업데이트\n",
        "for step in range(steps): \n",
        "    for i, j, r in non_zeros:\n",
        "        \n",
        "        eij = r - np.dot(P[i, :], Q[j, :].T)\n",
        "        \n",
        "        P[i,:] = P[i,:] + learning_rate * ( eij * Q[j,:] - r_lambda*P[i,:] )\n",
        "        Q[j,:] = Q[j,:] + learning_rate * ( eij * P[i,:] - r_lambda*Q[j,:] )\n",
        "\n",
        "    rmse = get_rmse(R, P, Q, non_zeros)\n",
        "    if (step % 50) == 0 :\n",
        "      print(\"### iteration step : \",step,\"rmse : \",rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StM-sK4epQL4",
        "outputId": "8b7ce162-d0d2-41af-88a8-d1c86dc53472"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### iteration step :  0 rmse :  3.2388050277987723\n",
            "### iteration step :  50 rmse :  0.4876723101369648\n",
            "### iteration step :  100 rmse :  0.1564340384819247\n",
            "### iteration step :  150 rmse :  0.07455141311978046\n",
            "### iteration step :  200 rmse :  0.04325226798579314\n",
            "### iteration step :  250 rmse :  0.029248328780878973\n",
            "### iteration step :  300 rmse :  0.022621116143829466\n",
            "### iteration step :  350 rmse :  0.019493636196525135\n",
            "### iteration step :  400 rmse :  0.018022719092132704\n",
            "### iteration step :  450 rmse :  0.01731968595344266\n",
            "### iteration step :  500 rmse :  0.016973657887570753\n",
            "### iteration step :  550 rmse :  0.016796804595895633\n",
            "### iteration step :  600 rmse :  0.01670132290188466\n",
            "### iteration step :  650 rmse :  0.01664473691247669\n",
            "### iteration step :  700 rmse :  0.016605910068210026\n",
            "### iteration step :  750 rmse :  0.016574200475705\n",
            "### iteration step :  800 rmse :  0.01654431582921597\n",
            "### iteration step :  850 rmse :  0.01651375177473524\n",
            "### iteration step :  900 rmse :  0.01648146573819501\n",
            "### iteration step :  950 rmse :  0.016447171683479155\n",
            "### iteration step :  1000 rmse :  0.016410959588961445\n",
            "### iteration step :  1050 rmse :  0.01637308966218993\n",
            "### iteration step :  1100 rmse :  0.016333882336881784\n",
            "### iteration step :  1150 rmse :  0.016293661274599174\n",
            "### iteration step :  1200 rmse :  0.01625272572302336\n",
            "### iteration step :  1250 rmse :  0.016211338984681307\n",
            "### iteration step :  1300 rmse :  0.016169725523756753\n",
            "### iteration step :  1350 rmse :  0.016128072491623933\n",
            "### iteration step :  1400 rmse :  0.016086533303745463\n",
            "### iteration step :  1450 rmse :  0.016045231961723017\n",
            "### iteration step :  1500 rmse :  0.016004267423347165\n",
            "### iteration step :  1550 rmse :  0.015963717671935662\n",
            "### iteration step :  1600 rmse :  0.01592364333325902\n",
            "### iteration step :  1650 rmse :  0.015884090797210332\n",
            "### iteration step :  1700 rmse :  0.01584509485896164\n",
            "### iteration step :  1750 rmse :  0.015806680922219037\n",
            "### iteration step :  1800 rmse :  0.01576886681829548\n",
            "### iteration step :  1850 rmse :  0.015731664296432853\n",
            "### iteration step :  1900 rmse :  0.0156950802377121\n",
            "### iteration step :  1950 rmse :  0.015659117639502156\n",
            "### iteration step :  2000 rmse :  0.01562377641126073\n",
            "### iteration step :  2050 rmse :  0.015589054016349555\n",
            "### iteration step :  2100 rmse :  0.015554945988861105\n",
            "### iteration step :  2150 rmse :  0.015521446349450352\n",
            "### iteration step :  2200 rmse :  0.015488547939747707\n",
            "### iteration step :  2250 rmse :  0.01545624269135677\n",
            "### iteration step :  2300 rmse :  0.015424521842295272\n",
            "### iteration step :  2350 rmse :  0.015393376111282013\n",
            "### iteration step :  2400 rmse :  0.015362795838183143\n",
            "### iteration step :  2450 rmse :  0.015332771097284762\n",
            "### iteration step :  2500 rmse :  0.015303291788717931\n",
            "### iteration step :  2550 rmse :  0.015274347712285622\n",
            "### iteration step :  2600 rmse :  0.015245928627081148\n",
            "### iteration step :  2650 rmse :  0.015218024299612717\n",
            "### iteration step :  2700 rmse :  0.01519062454260429\n",
            "### iteration step :  2750 rmse :  0.01516371924620075\n",
            "### iteration step :  2800 rmse :  0.015137298402981364\n",
            "### iteration step :  2850 rmse :  0.015111352127906257\n",
            "### iteration step :  2900 rmse :  0.015085870674095652\n",
            "### iteration step :  2950 rmse :  0.01506084444518256\n",
            "### iteration step :  3000 rmse :  0.015036264004844877\n",
            "### iteration step :  3050 rmse :  0.015012120083998748\n",
            "### iteration step :  3100 rmse :  0.01498840358605898\n",
            "### iteration step :  3150 rmse :  0.01496510559059199\n",
            "### iteration step :  3200 rmse :  0.014942217355656108\n",
            "### iteration step :  3250 rmse :  0.014919730319020604\n",
            "### iteration step :  3300 rmse :  0.01489763609849127\n",
            "### iteration step :  3350 rmse :  0.014875926491473183\n",
            "### iteration step :  3400 rmse :  0.014854593473919212\n",
            "### iteration step :  3450 rmse :  0.014833629198763576\n",
            "### iteration step :  3500 rmse :  0.014813025993944972\n",
            "### iteration step :  3550 rmse :  0.014792776360095143\n",
            "### iteration step :  3600 rmse :  0.014772872967945041\n",
            "### iteration step :  3650 rmse :  0.01475330865553506\n",
            "### iteration step :  3700 rmse :  0.014734076425243908\n",
            "### iteration step :  3750 rmse :  0.014715169440695331\n",
            "### iteration step :  3800 rmse :  0.014696581023572753\n",
            "### iteration step :  3850 rmse :  0.01467830465036814\n",
            "### iteration step :  3900 rmse :  0.014660333949087112\n",
            "### iteration step :  3950 rmse :  0.014642662695939187\n",
            "### iteration step :  4000 rmse :  0.014625284812012095\n",
            "### iteration step :  4050 rmse :  0.01460819435996789\n",
            "### iteration step :  4100 rmse :  0.014591385540748595\n",
            "### iteration step :  4150 rmse :  0.014574852690323055\n",
            "### iteration step :  4200 rmse :  0.014558590276459728\n",
            "### iteration step :  4250 rmse :  0.014542592895555768\n",
            "### iteration step :  4300 rmse :  0.014526855269506886\n",
            "### iteration step :  4350 rmse :  0.01451137224263225\n",
            "### iteration step :  4400 rmse :  0.01449613877865972\n",
            "### iteration step :  4450 rmse :  0.01448114995776735\n",
            "### iteration step :  4500 rmse :  0.014466400973686197\n",
            "### iteration step :  4550 rmse :  0.014451887130863955\n",
            "### iteration step :  4600 rmse :  0.014437603841691987\n",
            "### iteration step :  4650 rmse :  0.014423546623797264\n",
            "### iteration step :  4700 rmse :  0.014409711097395934\n",
            "### iteration step :  4750 rmse :  0.014396092982709248\n",
            "### iteration step :  4800 rmse :  0.014382688097442095\n",
            "### iteration step :  4850 rmse :  0.014369492354327223\n",
            "### iteration step :  4900 rmse :  0.014356501758723004\n",
            "### iteration step :  4950 rmse :  0.014343712406279092\n",
            "### iteration step :  5000 rmse :  0.014331120480660299\n",
            "### iteration step :  5050 rmse :  0.014318722251323433\n",
            "### iteration step :  5100 rmse :  0.014306514071356878\n",
            "### iteration step :  5150 rmse :  0.014294492375373094\n",
            "### iteration step :  5200 rmse :  0.014282653677457987\n",
            "### iteration step :  5250 rmse :  0.014270994569174628\n",
            "### iteration step :  5300 rmse :  0.014259511717616401\n",
            "### iteration step :  5350 rmse :  0.014248201863514512\n",
            "### iteration step :  5400 rmse :  0.01423706181939126\n",
            "### iteration step :  5450 rmse :  0.014226088467771594\n",
            "### iteration step :  5500 rmse :  0.014215278759425303\n",
            "### iteration step :  5550 rmse :  0.014204629711678884\n",
            "### iteration step :  5600 rmse :  0.014194138406747773\n",
            "### iteration step :  5650 rmse :  0.014183801990134531\n",
            "### iteration step :  5700 rmse :  0.01417361766905545\n",
            "### iteration step :  5750 rmse :  0.014163582710913203\n",
            "### iteration step :  5800 rmse :  0.014153694441813634\n",
            "### iteration step :  5850 rmse :  0.014143950245116632\n",
            "### iteration step :  5900 rmse :  0.0141343475600332\n",
            "### iteration step :  5950 rmse :  0.014124883880247905\n",
            "### iteration step :  6000 rmse :  0.014115556752591091\n",
            "### iteration step :  6050 rmse :  0.014106363775739877\n",
            "### iteration step :  6100 rmse :  0.014097302598953015\n",
            "### iteration step :  6150 rmse :  0.014088370920841385\n",
            "### iteration step :  6200 rmse :  0.014079566488169845\n",
            "### iteration step :  6250 rmse :  0.01407088709469682\n",
            "### iteration step :  6300 rmse :  0.014062330580034354\n",
            "### iteration step :  6350 rmse :  0.014053894828546331\n",
            "### iteration step :  6400 rmse :  0.014045577768272512\n",
            "### iteration step :  6450 rmse :  0.014037377369886158\n",
            "### iteration step :  6500 rmse :  0.0140292916456684\n",
            "### iteration step :  6550 rmse :  0.01402131864852231\n",
            "### iteration step :  6600 rmse :  0.01401345647100259\n",
            "### iteration step :  6650 rmse :  0.014005703244382219\n",
            "### iteration step :  6700 rmse :  0.013998057137729173\n",
            "### iteration step :  6750 rmse :  0.013990516357020002\n",
            "### iteration step :  6800 rmse :  0.01398307914427166\n",
            "### iteration step :  6850 rmse :  0.013975743776693264\n",
            "### iteration step :  6900 rmse :  0.01396850856586751\n",
            "### iteration step :  6950 rmse :  0.01396137185694408\n",
            "### iteration step :  7000 rmse :  0.013954332027865302\n",
            "### iteration step :  7050 rmse :  0.013947387488600476\n",
            "### iteration step :  7100 rmse :  0.01394053668040675\n",
            "### iteration step :  7150 rmse :  0.013933778075111267\n",
            "### iteration step :  7200 rmse :  0.013927110174402289\n",
            "### iteration step :  7250 rmse :  0.01392053150915238\n",
            "### iteration step :  7300 rmse :  0.01391404063874427\n",
            "### iteration step :  7350 rmse :  0.013907636150427338\n",
            "### iteration step :  7400 rmse :  0.013901316658681695\n",
            "### iteration step :  7450 rmse :  0.013895080804602509\n",
            "### iteration step :  7500 rmse :  0.013888927255298783\n",
            "### iteration step :  7550 rmse :  0.013882854703307622\n",
            "### iteration step :  7600 rmse :  0.013876861866024109\n",
            "### iteration step :  7650 rmse :  0.01387094748514887\n",
            "### iteration step :  7700 rmse :  0.01386511032613944\n",
            "### iteration step :  7750 rmse :  0.01385934917768834\n",
            "### iteration step :  7800 rmse :  0.013853662851201997\n",
            "### iteration step :  7850 rmse :  0.013848050180308056\n",
            "### iteration step :  7900 rmse :  0.013842510020358403\n",
            "### iteration step :  7950 rmse :  0.013837041247954849\n",
            "### iteration step :  8000 rmse :  0.013831642760483653\n",
            "### iteration step :  8050 rmse :  0.013826313475664922\n",
            "### iteration step :  8100 rmse :  0.013821052331108119\n",
            "### iteration step :  8150 rmse :  0.013815858283881774\n",
            "### iteration step :  8200 rmse :  0.01381073031009254\n",
            "### iteration step :  8250 rmse :  0.013805667404476866\n",
            "### iteration step :  8300 rmse :  0.013800668580000446\n",
            "### iteration step :  8350 rmse :  0.013795732867468909\n",
            "### iteration step :  8400 rmse :  0.013790859315145714\n",
            "### iteration step :  8450 rmse :  0.013786046988381907\n",
            "### iteration step :  8500 rmse :  0.01378129496925629\n",
            "### iteration step :  8550 rmse :  0.013776602356221078\n",
            "### iteration step :  8600 rmse :  0.01377196826375449\n",
            "### iteration step :  8650 rmse :  0.013767391822029278\n",
            "### iteration step :  8700 rmse :  0.013762872176581498\n",
            "### iteration step :  8750 rmse :  0.013758408487991588\n",
            "### iteration step :  8800 rmse :  0.0137539999315711\n",
            "### iteration step :  8850 rmse :  0.013749645697062225\n",
            "### iteration step :  8900 rmse :  0.01374534498832819\n",
            "### iteration step :  8950 rmse :  0.013741097023079494\n",
            "### iteration step :  9000 rmse :  0.013736901032575848\n",
            "### iteration step :  9050 rmse :  0.013732756261356473\n",
            "### iteration step :  9100 rmse :  0.013728661966969202\n",
            "### iteration step :  9150 rmse :  0.013724617419703945\n",
            "### iteration step :  9200 rmse :  0.013720621902338151\n",
            "### iteration step :  9250 rmse :  0.013716674709881046\n",
            "### iteration step :  9300 rmse :  0.013712775149333204\n",
            "### iteration step :  9350 rmse :  0.013708922539439035\n",
            "### iteration step :  9400 rmse :  0.013705116210458688\n",
            "### iteration step :  9450 rmse :  0.013701355503937637\n",
            "### iteration step :  9500 rmse :  0.013697639772479604\n",
            "### iteration step :  9550 rmse :  0.01369396837953047\n",
            "### iteration step :  9600 rmse :  0.013690340699165063\n",
            "### iteration step :  9650 rmse :  0.013686756115878097\n",
            "### iteration step :  9700 rmse :  0.013683214024377863\n",
            "### iteration step :  9750 rmse :  0.01367971382938824\n",
            "### iteration step :  9800 rmse :  0.013676254945456075\n",
            "### iteration step :  9850 rmse :  0.013672836796757345\n",
            "### iteration step :  9900 rmse :  0.013669458816912996\n",
            "### iteration step :  9950 rmse :  0.013666120448807181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_matrix=np.dot(P,Q.T)\n",
        "print('예측 행렬:\\n',np.round(pred_matrix,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq8N5KeQpQJK",
        "outputId": "9b612d16-3c2a-4206-aee2-76075e0e9242"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 행렬:\n",
            " [[3.991 1.951 1.108 1.998 1.569]\n",
            " [4.23  4.978 1.074 2.987 1.005]\n",
            " [5.028 2.487 2.988 3.98  3.985]\n",
            " [4.974 2.002 1.003 2.002 1.555]]\n"
          ]
        }
      ]
    }
  ]
}